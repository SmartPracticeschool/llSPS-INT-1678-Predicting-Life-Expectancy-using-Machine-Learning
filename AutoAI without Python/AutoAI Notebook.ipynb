{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "### IBM AutoAI-SDK Auto-Generated Notebook v1.12.2\n\n**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered,   \nthere is no guarantee it will successfully execute. This pipeline is optimized for the original dataset.  \nThe pipeline may fail or produce sub-optimium results if used with different data. For different data,  \nplease consider returning to AutoAI Experiments to generate a new pipeline. Please read our documentation   \nfor more information:   \n<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>  \n\n\nBefore modifying the pipeline or trying to re-fit the pipeline, consider:   \nThe notebook converts dataframes to numpy arrays before fitting the pipeline   \n(a current restriction of the preprocessor pipeline). The known_values_list is passed by reference   \nand populated with categorical values during fit of the preprocessing pipeline. Delete its members before re-fitting."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"content\"></a>\n## Notebook content\n\nThis notebook contains steps and code to demonstrate AutoAI pipeline. This notebook introduces commands for getting data,  \npipeline model, model inspection and testing.\n\nSome familiarity with Python is helpful. This notebook uses Python 3."}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "## Notebook goals\n\n-  inspection of trained pipeline via graphical vizualization and source code preview.\n-  pipeline evaluation.\n-  pipeline deployment and webservice scoring\n\n## Contents\n\nThis notebook contains the following parts:\n\n1.\t[Setup](#setup)         \n    a.  [AutoAI experiment metadata](#variables_definition)      \n2.\t[Pipeline inspection](#inspection)      \n    a.  [Get historical optimizer instance](#get_hist_and_train)      \n    b.  [Get pipeline model](#get_pipeline)      \n    c.  [Preview pipeline model as python code](#preview_model_to_python_code)      \n    d.  [Visualize pipeline model](#visualize_pipeline)      \n    e.  [Read training and holdout data](#train_holdout_read)        \n    f.  [Test pipeline model locally](#test_model)       \n3.\t[Pipeline refinery](#refinery)       \n    a.  [Pipeline definition source code](#pipeline_definition)      \n    b.  [Lale library](#lale_library)      \n4.\t[Deploy and score](#scoring)       \n    a.  [Insert WML credentials](#wml_credentials)   \n    b.  [Create deployment](#deployment)      \n    c.  [Score webservice](#online_scoring)        \n    d.  [Delete deployment](#delete_deployment)       \n5.  [Authors](#authors)      "}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n# Setup\n\nBefore you use the sample code in this notebook, you must perform the following setup tasks:\n - `watson-machine-learning-client` uninstallation of the old client\n - `watson-machine-learning-client-V4` installation\n - `autoai-libs` installation/upgrade\n - `lightgbm` or `xgboost` installation/downgrade if they are needed"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip uninstall watson-machine-learning-client -y", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Uninstalling watson-machine-learning-client-1.0.376:\n  Successfully uninstalled watson-machine-learning-client-1.0.376\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U watson-machine-learning-client-V4", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client-V4\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/9a/cd255fb8e3a67a688c36748233eb57ac4a4331fa574ef678c3cd69e14e44/watson_machine_learning_client_V4-1.0.99-py3-none-any.whl (1.2MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.2MB 8.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (1.24.1)\nRequirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.3.3)\nRequirement already satisfied, skipping upgrade: pandas<=0.25.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.24.1)\nRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (0.8.2)\nCollecting ibm-cos-sdk==2.6.0 (from watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/91/86b2816c7b77d816b03a1ad6cf7db4b1f67556af395d5b93fdae6086c933/ibm-cos-sdk-2.6.0.tar.gz (53kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 12.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2.21.0)\nRequirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client-V4) (2020.4.5.1)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->watson-machine-learning-client-V4) (1.12.0)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (2.7.5)\nRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (1.15.4)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<=0.25.3->watson-machine-learning-client-V4) (2018.9)\nCollecting ibm-cos-sdk-core==2.6.0 (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/c1/c823507c472bf88dbd045445df6850744111d34fd218c6ea3b9c9bde2cfe/ibm-cos-sdk-core-2.6.0.tar.gz (763kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 768kB 19.5MB/s eta 0:00:01\n\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.6.0 (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/92/682a28b99777a3fdc65e6d5641ed7e1ca470d0eab3bb2826cc30c6b60e21/ibm-cos-sdk-s3transfer-2.6.0.tar.gz (221kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 225kB 20.6MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4) (0.9.3)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (2.8)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client-V4) (3.0.4)\nRequirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.6.0->ibm-cos-sdk==2.6.0->watson-machine-learning-client-V4) (0.14)\nBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/37/9c/c4/a2c610ccb877d37c2cb87a5bfe55845fecffd6bb01bcd5e9d5\n  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/75/93/e6/23071b2c037147a0993d34b64a03e51abca84435fc9cd6a278\n  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/23/d9/d7/43fd95b014eed89466154d8373bf4cffbb3d972de7841e213c\nSuccessfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\nInstalling collected packages: ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, watson-machine-learning-client-V4\n  Found existing installation: ibm-cos-sdk-core 2.4.3\n    Uninstalling ibm-cos-sdk-core-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-core-2.4.3\n  Found existing installation: ibm-cos-sdk-s3transfer 2.4.3\n    Uninstalling ibm-cos-sdk-s3transfer-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-s3transfer-2.4.3\n  Found existing installation: ibm-cos-sdk 2.4.3\n    Uninstalling ibm-cos-sdk-2.4.3:\n      Successfully uninstalled ibm-cos-sdk-2.4.3\nSuccessfully installed ibm-cos-sdk-2.6.0 ibm-cos-sdk-core-2.6.0 ibm-cos-sdk-s3transfer-2.6.0 watson-machine-learning-client-V4-1.0.99\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip install -U autoai-libs", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Collecting autoai-libs\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/cb/4144b9ee74fcb058cea934478c87f2444cfa7b38a01396507f1a417030cb/autoai_libs-1.10.12-37-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.3MB 8.6MB/s eta 0:00:01\n\u001b[?25hCollecting category-encoders==2.1.0 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 14.8MB/s ta 0:00:01\n\u001b[?25hCollecting numpy>=1.16.4 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/a9/b1bc4c935ed063766bce7d3e8c7b20bd52e515ff1c732b02caacf7918e5a/numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20.1MB 48.6MB/s eta 0:00:01\n\u001b[?25hCollecting pandas<1.0.0,>=0.24.2 (from autoai-libs)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10.4MB 33.9MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn==0.20.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from autoai-libs) (0.20.3)\nRequirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from category-encoders==2.1.0->autoai-libs) (1.2.0)\nRequirement already satisfied, skipping upgrade: patsy>=0.4.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from category-encoders==2.1.0->autoai-libs) (0.5.1)\nRequirement already satisfied, skipping upgrade: statsmodels>=0.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from category-encoders==2.1.0->autoai-libs) (0.9.0)\nRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2018.9)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas<1.0.0,>=0.24.2->autoai-libs) (2.7.5)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from patsy>=0.4.1->category-encoders==2.1.0->autoai-libs) (1.12.0)\n\u001b[31mERROR: tensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\nInstalling collected packages: numpy, pandas, category-encoders, autoai-libs\n  Found existing installation: numpy 1.15.4\n    Uninstalling numpy-1.15.4:\n      Successfully uninstalled numpy-1.15.4\n  Found existing installation: pandas 0.24.1\n    Uninstalling pandas-0.24.1:\n      Successfully uninstalled pandas-0.24.1\n  Found existing installation: category-encoders 2.0.0\n    Uninstalling category-encoders-2.0.0:\n      Successfully uninstalled category-encoders-2.0.0\n  Found existing installation: autoai-libs 1.10.5\n    Uninstalling autoai-libs-1.10.5:\n      Successfully uninstalled autoai-libs-1.10.5\nSuccessfully installed autoai-libs-1.10.12 category-encoders-2.1.0 numpy-1.18.5 pandas-0.25.3\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"variables_definition\"></a>\n### AutoAI experiment metadata\n\nThis cell contains input parameters provided to run the AutoAI experiment in Watson Studio and COS credentials required to retrieve AutoAI pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.helpers import DataConnection, S3Connection, S3Location\n\nexperiment_metadata = dict(\n   prediction_type='regression',\n   prediction_column='life',\n   test_size=0.1,\n   scoring='neg_root_mean_squared_error',\n   max_number_of_estimators=2,\n   training_data_reference = [DataConnection(\n        connection=S3Connection(\n            api_key='A3ithPg9UJeRnOqsZNC9Y7VihX-yYoE4KSDfTOftN9cw',\n            auth_endpoint='https://iam.bluemix.net/oidc/token/',\n            endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n        ),\n            location=S3Location(\n            bucket='autoailifeexpectancy-donotdelete-pr-mrvv832wudcqol',\n            path='lifeexpect.csv'\n        ))\n    ],\n    training_result_reference = DataConnection(\n        connection=S3Connection(\n            api_key='A3ithPg9UJeRnOqsZNC9Y7VihX-yYoE4KSDfTOftN9cw',\n            auth_endpoint='https://iam.bluemix.net/oidc/token/',\n            endpoint_url='https://s3.eu-geo.objectstorage.softlayer.net'\n        ),\n        location=S3Location(\n            bucket='autoailifeexpectancy-donotdelete-pr-mrvv832wudcqol',\n            path='auto_ml/b06ae200-bef5-4b6d-81a4-4f50876defac/wml_data/603bb907-cb6b-431d-b9f0-2c7fbb46b04f/data/automl',\n            model_location='auto_ml/b06ae200-bef5-4b6d-81a4-4f50876defac/wml_data/603bb907-cb6b-431d-b9f0-2c7fbb46b04f/data/automl/cognito_output/Pipeline5/model.pickle',\n            training_status='auto_ml/b06ae200-bef5-4b6d-81a4-4f50876defac/wml_data/603bb907-cb6b-431d-b9f0-2c7fbb46b04f/training-status.json'\n        )\n    ))\n\npipeline_name='Pipeline_7'", "execution_count": 4, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"inspection\"></a>\n## Pipeline inspection\nIn this section you will get the trained pipeline model from the AutoAI experiment and inspect it.  \nYou will see pipeline as a pythone code, graphically visualized and at the end, you will perform a local test.\n"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_hist_and_train\"></a>\n### Get historical optimizer instance\n\nThe next cell contains code for retrieving fitted optimizer."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.experiment import AutoAI\n\noptimizer = AutoAI().runs.get_optimizer(metadata=experiment_metadata)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "Warning: To use AutoAI with xgboost estimators, you need to have xgboost 0.90 installed.\nWarning: To use AutoAI with lightgbm estimators, you need to have lightgbm 2.2.3 installed.\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"get_pipeline\"></a>\n### Get pipeline model\n\nThe following cell loads selected AutoAI pipeline model. If you want to get pure scikit-learn pipeline specify `as_type='sklearn'` parameter. By default enriched scikit-learn pipeline is returned `as_type='lale'`."}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model = optimizer.get_pipeline(pipeline_name=pipeline_name)", "execution_count": 6, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"preview_model_to_python_code\"></a>\n### Preview pipeline model as python code\nIn the next cell, downloaded pipeline model could be previewed as a python code.  \nYou will be able to see what exact steps are involved in model creation."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.pretty_print(combinators=False, ipython_display=True)", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "```python\nfrom lale.lib.autoai_libs import NumpyColumnSelector\nfrom lale.lib.autoai_libs import CompressStrings\nfrom lale.lib.autoai_libs import NumpyReplaceMissingValues\nfrom lale.lib.autoai_libs import NumpyReplaceUnknownValues\nfrom lale.lib.autoai_libs import boolean2float\nfrom lale.lib.autoai_libs import CatImputer\nfrom lale.lib.autoai_libs import CatEncoder\nimport numpy as np\nfrom lale.lib.autoai_libs import float32_transform\nfrom lale.operators import make_pipeline\nfrom lale.lib.autoai_libs import FloatStr2Float\nfrom lale.lib.autoai_libs import NumImputer\nfrom lale.lib.autoai_libs import OptStandardScaler\nfrom lale.operators import make_union\nfrom lale.lib.autoai_libs import NumpyPermuteArray\nfrom lale.lib.autoai_libs import TA1\nimport autoai_libs.utils.fc_methods\nfrom lale.lib.autoai_libs import FS1\nimport autoai_libs.cognito.transforms.textras_methods\nfrom lale.lib.sklearn import ExtraTreesRegressor\n\nnumpy_column_selector_0 = NumpyColumnSelector(columns=[0, 5, 9, 11])\ncompress_strings = CompressStrings(compress_type='hash', dtypes_list=['float_int_num', 'float_int_num', 'float_int_num', 'float_int_num'], missing_values_reference_list=['', '-', '?', float('nan')], misslist_list=[[], [], [], []])\nnumpy_replace_missing_values_0 = NumpyReplaceMissingValues(filling_values=100001, missing_values=[])\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=100001, filling_values_list=[100001, 100001, 100001, 100001], known_values_list=[[0.0, 1.0], [0.0, 1.0, 2.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 11.0, 12.0, 14.0, 15.0, 16.0, 17.0, 18.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 31.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], [0.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 17.0, 23.0, 24.0, 26.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], [0.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 16.0, 19.0, 21.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0]], missing_values_reference_list=['', '-', '?', float('nan')])\ncat_imputer = CatImputer(missing_values=100001, sklearn_version_family='20', strategy='most_frequent')\ncat_encoder = CatEncoder(dtype=np.float64, handle_unknown='error', sklearn_version_family='20')\npipeline_0 = make_pipeline(numpy_column_selector_0, compress_strings, numpy_replace_missing_values_0, numpy_replace_unknown_values, boolean2float(), cat_imputer, cat_encoder, float32_transform())\nnumpy_column_selector_1 = NumpyColumnSelector(columns=[1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18])\nfloat_str2_float = FloatStr2Float(dtypes_list=['float_int_num', 'float_int_num', 'float_num', 'float_num', 'float_int_num', 'float_num', 'float_int_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num', 'float_num'], missing_values_reference_list=[])\nnumpy_replace_missing_values_1 = NumpyReplaceMissingValues(filling_values=float('nan'), missing_values=[])\nnum_imputer = NumImputer(missing_values=float('nan'), strategy='median')\nopt_standard_scaler = OptStandardScaler(num_scaler_copy=None, num_scaler_with_mean=None, num_scaler_with_std=None, use_scaler_flag=False)\npipeline_1 = make_pipeline(numpy_column_selector_1, float_str2_float, numpy_replace_missing_values_1, num_imputer, opt_standard_scaler, float32_transform())\nunion = make_union(pipeline_0, pipeline_1)\nnumpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 5, 9, 11, 1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18])\nta1_0 = TA1(fun=np.sin, name='sin', datatypes=['float'], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=['status', 'adultmortality', 'infantdeaths', 'alcohol', 'percentageexpenditure', 'hepatitisb', 'measles', 'bmi', 'underfivedeaths', 'polio', 'totalexpenditure', 'dip', 'hiv/aids', 'gdp', 'population', 'thinness119', 'thinness59', 'incomecomp', 'schooling'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_0 = FS1(cols_ids_must_keep=range(0, 19), additional_col_count_to_keep=15, ptype='regression')\nta1_1 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name='sigmoid', datatypes=['numeric'], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=['status', 'adultmortality', 'infantdeaths', 'alcohol', 'percentageexpenditure', 'hepatitisb', 'measles', 'bmi', 'underfivedeaths', 'polio', 'totalexpenditure', 'dip', 'hiv/aids', 'gdp', 'population', 'thinness119', 'thinness59', 'incomecomp', 'schooling', 'sin(infantdeaths)', 'sin(alcohol)', 'sin(percentageexpenditure)', 'sin(measles)', 'sin(bmi)', 'sin(underfivedeaths)', 'sin(polio)', 'sin(totalexpenditure)', 'sin(dip)', 'sin(hiv/aids)', 'sin(population)', 'sin(thinness119)', 'sin(thinness59)', 'sin(incomecomp)', 'sin(schooling)'], col_dtypes=[np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32'), np.dtype('float32')])\nfs1_1 = FS1(cols_ids_must_keep=range(0, 19), additional_col_count_to_keep=15, ptype='regression')\nextra_trees_regressor = ExtraTreesRegressor(bootstrap=True, n_jobs=4, oob_score=True, random_state=33)\npipeline = make_pipeline(union, numpy_permute_array, ta1_0, fs1_0, ta1_1, fs1_1, extra_trees_regressor)\n```"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"visualize_pipeline\"></a>\n### Visualize pipeline model\n\nPreview pipeline model stages as graph. Each node's name links to detailed description of the stage.\n"}, {"metadata": {"pycharm": {"is_executing": false, "name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.visualize()", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<graphviz.dot.Digraph at 0x7f6938261470>", "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"1688pt\" height=\"149pt\"\n viewBox=\"0.00 0.00 1688.09 148.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 144.5391)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-144.5391 1684.0874,-144.5391 1684.0874,4 -4,4\"/>\n</a>\n</g>\n<!-- numpy_column_selector_0 -->\n<g id=\"node1\" class=\"node\">\n<title>numpy_column_selector_0</title>\n<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" xlink:title=\"numpy_column_selector_0 = NumpyColumnSelector(columns=[0, 5, 9, 11])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"39.598\" cy=\"-103.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-112.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-100.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"39.598\" y=\"-88.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- compress_strings -->\n<g id=\"node2\" class=\"node\">\n<title>compress_strings</title>\n<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.compress_strings.html\" xlink:title=\"compress_strings = CompressStrings(compress_type=&#39;hash&#39;, dtypes_list=[&#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;], missing_values_reference_list=[&#39;&#39;, &#39;&#45;&#39;, &#39;?&#39;, float(&#39;nan&#39;)], misslist_list=[[], [], [], []])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"163.9863\" cy=\"-103.7696\" rx=\"48.5816\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"163.9863\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Compress&#45;</text>\n<text text-anchor=\"middle\" x=\"163.9863\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Strings</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_0&#45;&gt;compress_strings -->\n<g id=\"edge1\" class=\"edge\">\n<title>numpy_column_selector_0&#45;&gt;compress_strings</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M79.2972,-103.7696C87.4737,-103.7696 96.2497,-103.7696 104.9433,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.0703,-107.2697 115.0702,-103.7696 105.0702,-100.2697 105.0703,-107.2697\"/>\n</g>\n<!-- numpy_replace_missing_values_0 -->\n<g id=\"node3\" class=\"node\">\n<title>numpy_replace_missing_values_0</title>\n<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" xlink:title=\"numpy_replace_missing_values_0 = NumpyReplaceMissingValues(filling_values=100001, missing_values=[])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"288.3747\" cy=\"-103.7696\" rx=\"39.6962\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-118.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-82.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- compress_strings&#45;&gt;numpy_replace_missing_values_0 -->\n<g id=\"edge2\" class=\"edge\">\n<title>compress_strings&#45;&gt;numpy_replace_missing_values_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M212.7909,-103.7696C221.2105,-103.7696 229.9737,-103.7696 238.4231,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.5296,-107.2697 248.5296,-103.7696 238.5296,-100.2697 238.5296,-107.2697\"/>\n</g>\n<!-- numpy_replace_unknown_values -->\n<g id=\"node4\" class=\"node\">\n<title>numpy_replace_unknown_values</title>\n<g id=\"a_node4\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_unknown_values.html\" xlink:title=\"numpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=100001, filling_values_list=[100001, 100001, 100001, 100001], known_values_list=[[0.0, 1.0], [0.0, 1.0, 2.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 11.0, 12.0, 14.0, 15.0, 16.0, 17.0, 18.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 31...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"410.6417\" cy=\"-103.7696\" rx=\"46.8387\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-118.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Unknown&#45;</text>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-82.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values -->\n<g id=\"edge3\" class=\"edge\">\n<title>numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M328.0713,-103.7696C336.2906,-103.7696 345.1018,-103.7696 353.7968,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.9081,-107.2697 363.9081,-103.7696 353.908,-100.2697 353.9081,-107.2697\"/>\n</g>\n<!-- boolean2float -->\n<g id=\"node5\" class=\"node\">\n<title>boolean2float</title>\n<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.boolean2float.html\" xlink:title=\"boolean2float = boolean2float()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"541.3122\" cy=\"-100.7696\" rx=\"48.0029\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"541.3122\" y=\"-97.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">boolean2float</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_unknown_values&#45;&gt;boolean2float -->\n<g id=\"edge4\" class=\"edge\">\n<title>numpy_replace_unknown_values&#45;&gt;boolean2float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M457.4477,-102.695C465.6736,-102.5061 474.3268,-102.3074 482.8237,-102.1124\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"483.1545,-105.6058 493.0715,-101.8771 482.9938,-98.6076 483.1545,-105.6058\"/>\n</g>\n<!-- cat_imputer -->\n<g id=\"node6\" class=\"node\">\n<title>cat_imputer</title>\n<g id=\"a_node6\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_imputer.html\" xlink:title=\"cat_imputer = CatImputer(missing_values=100001, sklearn_version_family=&#39;20&#39;, strategy=&#39;most_frequent&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"663.4974\" cy=\"-98.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"663.4974\" y=\"-101.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"663.4974\" y=\"-89.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- boolean2float&#45;&gt;cat_imputer -->\n<g id=\"edge5\" class=\"edge\">\n<title>boolean2float&#45;&gt;cat_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M589.603,-99.9791C597.8577,-99.844 606.4389,-99.7035 614.7066,-99.5682\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"615.0217,-103.0636 624.963,-99.4003 614.9071,-96.0645 615.0217,-103.0636\"/>\n</g>\n<!-- cat_encoder -->\n<g id=\"node7\" class=\"node\">\n<title>cat_encoder</title>\n<g id=\"a_node7\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_encoder.html\" xlink:title=\"cat_encoder = CatEncoder(dtype=np.float64, handle_unknown=&#39;error&#39;, sklearn_version_family=&#39;20&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"783.6431\" cy=\"-97.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"783.6431\" y=\"-100.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"783.6431\" y=\"-88.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Encoder</text>\n</a>\n</g>\n</g>\n<!-- cat_imputer&#45;&gt;cat_encoder -->\n<g id=\"edge6\" class=\"edge\">\n<title>cat_imputer&#45;&gt;cat_encoder</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M701.8426,-98.4504C712.4636,-98.362 724.1318,-98.2649 735.2455,-98.1724\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.2796,-101.6723 745.2501,-98.0891 735.2213,-94.6726 735.2796,-101.6723\"/>\n</g>\n<!-- float32_transform_0 -->\n<g id=\"node8\" class=\"node\">\n<title>float32_transform_0</title>\n<g id=\"a_node8\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" xlink:title=\"float32_transform_0 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"910.8599\" cy=\"-94.7696\" rx=\"45.011\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"910.8599\" y=\"-97.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"910.8599\" y=\"-85.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- cat_encoder&#45;&gt;float32_transform_0 -->\n<g id=\"edge7\" class=\"edge\">\n<title>cat_encoder&#45;&gt;float32_transform_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M821.8123,-96.8695C832.3469,-96.621 843.996,-96.3463 855.3005,-96.0797\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"855.6287,-99.5731 865.5434,-95.8382 855.4636,-92.575 855.6287,-99.5731\"/>\n</g>\n<!-- concat_features -->\n<g id=\"node15\" class=\"node\">\n<title>concat_features</title>\n<g id=\"a_node15\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lale.concat_features.html\" xlink:title=\"concat_features = ConcatFeatures()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1032.4198\" cy=\"-68.7696\" rx=\"40.1111\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1032.4198\" y=\"-71.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Concat&#45;</text>\n<text text-anchor=\"middle\" x=\"1032.4198\" y=\"-59.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Features</text>\n</a>\n</g>\n</g>\n<!-- float32_transform_0&#45;&gt;concat_features -->\n<g id=\"edge13\" class=\"edge\">\n<title>float32_transform_0&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M951.6757,-86.0396C962.4485,-83.7354 974.1626,-81.23 985.2412,-78.8604\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"986.1448,-82.2464 995.1916,-76.7322 984.6807,-75.4012 986.1448,-82.2464\"/>\n</g>\n<!-- numpy_column_selector_1 -->\n<g id=\"node9\" class=\"node\">\n<title>numpy_column_selector_1</title>\n<g id=\"a_node9\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" xlink:title=\"numpy_column_selector_1 = NumpyColumnSelector(columns=[1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"288.3747\" cy=\"-31.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-28.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"288.3747\" y=\"-16.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float -->\n<g id=\"node10\" class=\"node\">\n<title>float_str2_float</title>\n<g id=\"a_node10\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float_str2_float.html\" xlink:title=\"float_str2_float = FloatStr2Float(dtypes_list=[&#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_int_num&#39;, &#39;float_num&#39;, &#39;float_int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;], missing_values_reference_li...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"410.6417\" cy=\"-31.7696\" rx=\"28.0702\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float&#45;</text>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-28.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Str2&#45;</text>\n<text text-anchor=\"middle\" x=\"410.6417\" y=\"-16.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_1&#45;&gt;float_str2_float -->\n<g id=\"edge8\" class=\"edge\">\n<title>numpy_column_selector_1&#45;&gt;float_str2_float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M328.0713,-31.7696C342.0737,-31.7696 357.7941,-31.7696 371.7309,-31.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"371.9828,-35.2697 381.9828,-31.7696 371.9827,-28.2697 371.9828,-35.2697\"/>\n</g>\n<!-- numpy_replace_missing_values_1 -->\n<g id=\"node11\" class=\"node\">\n<title>numpy_replace_missing_values_1</title>\n<g id=\"a_node11\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" xlink:title=\"numpy_replace_missing_values_1 = NumpyReplaceMissingValues(filling_values=float(&#39;nan&#39;), missing_values=[])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"541.3122\" cy=\"-36.7696\" rx=\"39.6962\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"541.3122\" y=\"-51.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"541.3122\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"541.3122\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"541.3122\" y=\"-15.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float&#45;&gt;numpy_replace_missing_values_1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>float_str2_float&#45;&gt;numpy_replace_missing_values_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M438.9953,-32.8545C454.3054,-33.4403 473.6552,-34.1807 491.3963,-34.8596\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"491.4868,-38.3655 501.6134,-35.2505 491.7546,-31.3706 491.4868,-38.3655\"/>\n</g>\n<!-- num_imputer -->\n<g id=\"node12\" class=\"node\">\n<title>num_imputer</title>\n<g id=\"a_node12\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.num_imputer.html\" xlink:title=\"num_imputer = NumImputer(missing_values=float(&#39;nan&#39;), strategy=&#39;median&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"663.4974\" cy=\"-39.7696\" rx=\"38.3684\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"663.4974\" y=\"-42.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Num&#45;</text>\n<text text-anchor=\"middle\" x=\"663.4974\" y=\"-30.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_1&#45;&gt;num_imputer -->\n<g id=\"edge10\" class=\"edge\">\n<title>numpy_replace_missing_values_1&#45;&gt;num_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M580.9822,-37.7436C591.8657,-38.0108 603.7878,-38.3035 615.102,-38.5813\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"615.1916,-42.0845 625.2745,-38.8311 615.3634,-35.0866 615.1916,-42.0845\"/>\n</g>\n<!-- opt_standard_scaler -->\n<g id=\"node13\" class=\"node\">\n<title>opt_standard_scaler</title>\n<g id=\"a_node13\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.opt_standard_scaler.html\" xlink:title=\"opt_standard_scaler = OptStandardScaler(num_scaler_copy=None, num_scaler_with_mean=None, num_scaler_with_std=None, use_scaler_flag=False)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"783.6431\" cy=\"-41.7696\" rx=\"45.9239\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"783.6431\" y=\"-50.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Opt&#45;</text>\n<text text-anchor=\"middle\" x=\"783.6431\" y=\"-38.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Standard&#45;</text>\n<text text-anchor=\"middle\" x=\"783.6431\" y=\"-26.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Scaler</text>\n</a>\n</g>\n</g>\n<!-- num_imputer&#45;&gt;opt_standard_scaler -->\n<g id=\"edge11\" class=\"edge\">\n<title>num_imputer&#45;&gt;opt_standard_scaler</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M701.8426,-40.4079C710.0363,-40.5443 718.8534,-40.691 727.5582,-40.8359\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"727.6245,-44.3374 737.6814,-41.0045 727.7411,-37.3384 727.6245,-44.3374\"/>\n</g>\n<!-- float32_transform_1 -->\n<g id=\"node14\" class=\"node\">\n<title>float32_transform_1</title>\n<g id=\"a_node14\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" xlink:title=\"float32_transform_1 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"910.8599\" cy=\"-45.7696\" rx=\"45.011\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"910.8599\" y=\"-48.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"910.8599\" y=\"-36.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- opt_standard_scaler&#45;&gt;float32_transform_1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>opt_standard_scaler&#45;&gt;float32_transform_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M829.5713,-43.2136C837.9606,-43.4774 846.7956,-43.7552 855.4265,-44.0266\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"855.3206,-47.5249 865.4256,-44.341 855.5406,-40.5284 855.3206,-47.5249\"/>\n</g>\n<!-- float32_transform_1&#45;&gt;concat_features -->\n<g id=\"edge14\" class=\"edge\">\n<title>float32_transform_1&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M952.6939,-53.6848C962.9988,-55.6346 974.111,-57.7371 984.6722,-59.7354\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"984.1085,-63.1907 994.5849,-61.6109 985.4099,-56.3128 984.1085,-63.1907\"/>\n</g>\n<!-- numpy_permute_array -->\n<g id=\"node16\" class=\"node\">\n<title>numpy_permute_array</title>\n<g id=\"a_node16\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_permute_array.html\" xlink:title=\"numpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 5, 9, 11, 1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1151.1513\" cy=\"-68.7696\" rx=\"42.3529\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1151.1513\" y=\"-77.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"1151.1513\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Permute&#45;</text>\n<text text-anchor=\"middle\" x=\"1151.1513\" y=\"-53.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Array</text>\n</a>\n</g>\n</g>\n<!-- concat_features&#45;&gt;numpy_permute_array -->\n<g id=\"edge15\" class=\"edge\">\n<title>concat_features&#45;&gt;numpy_permute_array</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1072.9484,-68.7696C1081.0676,-68.7696 1089.7112,-68.7696 1098.1793,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1098.3744,-72.2697 1108.3743,-68.7696 1098.3743,-65.2697 1098.3744,-72.2697\"/>\n</g>\n<!-- ta1_0 -->\n<g id=\"node17\" class=\"node\">\n<title>ta1_0</title>\n<g id=\"a_node17\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_0 = TA1(fun=np.sin, name=&#39;sin&#39;, datatypes=[&#39;float&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;status&#39;, &#39;adultmortality&#39;, &#39;infantdeaths&#39;, &#39;alcohol&#39;, &#39;percentageexpenditure&#39;, &#39;hepatitisb&#39;, &#39;measles&#39;, &#39;bmi&#39;, &#39;underfivedeaths...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1256.5777\" cy=\"-68.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1256.5777\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- numpy_permute_array&#45;&gt;ta1_0 -->\n<g id=\"edge16\" class=\"edge\">\n<title>numpy_permute_array&#45;&gt;ta1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1193.7284,-68.7696C1202.1666,-68.7696 1210.965,-68.7696 1219.2139,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1219.3004,-72.2697 1229.3003,-68.7696 1219.3003,-65.2697 1219.3004,-72.2697\"/>\n</g>\n<!-- fs1_0 -->\n<g id=\"node18\" class=\"node\">\n<title>fs1_0</title>\n<g id=\"a_node18\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_0 = FS1(cols_ids_must_keep=range(0, 19), additional_col_count_to_keep=15, ptype=&#39;regression&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1346.5777\" cy=\"-68.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1346.5777\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_0&#45;&gt;fs1_0 -->\n<g id=\"edge17\" class=\"edge\">\n<title>ta1_0&#45;&gt;fs1_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1283.5807,-68.7696C1291.6054,-68.7696 1300.5442,-68.7696 1309.1086,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1309.2828,-72.2697 1319.2827,-68.7696 1309.2827,-65.2697 1309.2828,-72.2697\"/>\n</g>\n<!-- ta1_1 -->\n<g id=\"node19\" class=\"node\">\n<title>ta1_1</title>\n<g id=\"a_node19\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.ta1.html\" xlink:title=\"ta1_1 = TA1(fun=autoai_libs.cognito.transforms.textras_methods.sigmoid, name=&#39;sigmoid&#39;, datatypes=[&#39;numeric&#39;], feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical], col_names=[&#39;status&#39;, &#39;adultmortality&#39;, &#39;infantdeaths&#39;, &#39;alcohol&#39;, &#39;percentageexpendit...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1436.5777\" cy=\"-68.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1436.5777\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">TA1</text>\n</a>\n</g>\n</g>\n<!-- fs1_0&#45;&gt;ta1_1 -->\n<g id=\"edge18\" class=\"edge\">\n<title>fs1_0&#45;&gt;ta1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1373.5807,-68.7696C1381.6054,-68.7696 1390.5442,-68.7696 1399.1086,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1399.2828,-72.2697 1409.2827,-68.7696 1399.2827,-65.2697 1399.2828,-72.2697\"/>\n</g>\n<!-- fs1_1 -->\n<g id=\"node20\" class=\"node\">\n<title>fs1_1</title>\n<g id=\"a_node20\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.fs1.html\" xlink:title=\"fs1_1 = FS1(cols_ids_must_keep=range(0, 19), additional_col_count_to_keep=15, ptype=&#39;regression&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1526.5777\" cy=\"-68.7696\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1526.5777\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">FS1</text>\n</a>\n</g>\n</g>\n<!-- ta1_1&#45;&gt;fs1_1 -->\n<g id=\"edge19\" class=\"edge\">\n<title>ta1_1&#45;&gt;fs1_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1463.5807,-68.7696C1471.6054,-68.7696 1480.5442,-68.7696 1489.1086,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1489.2828,-72.2697 1499.2827,-68.7696 1489.2827,-65.2697 1489.2828,-72.2697\"/>\n</g>\n<!-- extra_trees_regressor -->\n<g id=\"node21\" class=\"node\">\n<title>extra_trees_regressor</title>\n<g id=\"a_node21\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.sklearn.extra_trees_regressor.html\" xlink:title=\"extra_trees_regressor = ExtraTreesRegressor(bootstrap=True, n_jobs=4, oob_score=True, random_state=33)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1634.8325\" cy=\"-68.7696\" rx=\"45.011\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1634.8325\" y=\"-77.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Extra&#45;</text>\n<text text-anchor=\"middle\" x=\"1634.8325\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Trees&#45;</text>\n<text text-anchor=\"middle\" x=\"1634.8325\" y=\"-53.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Regressor</text>\n</a>\n</g>\n</g>\n<!-- fs1_1&#45;&gt;extra_trees_regressor -->\n<g id=\"edge20\" class=\"edge\">\n<title>fs1_1&#45;&gt;extra_trees_regressor</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1553.6157,-68.7696C1561.442,-68.7696 1570.2862,-68.7696 1579.1853,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1579.2047,-72.2697 1589.2046,-68.7696 1579.2046,-65.2697 1579.2047,-72.2697\"/>\n</g>\n</g>\n</svg>\n"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"train_holdout_read\"></a>\n### Read training and holdout data\n\nRetrieve training dataset from AutoAI experiment as pandas DataFrame."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "training_df, holdout_df = optimizer.get_data_connections()[0].read(with_holdout_split=True)\n\ntrain_X = training_df.drop([experiment_metadata['prediction_column']], axis=1).values\ntrain_y = training_df[experiment_metadata['prediction_column']].values\n\ntest_X = holdout_df.drop([experiment_metadata['prediction_column']], axis=1).values\ny_true = holdout_df[experiment_metadata['prediction_column']].values", "execution_count": 9, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"test_model\"></a>\n### Test pipeline model locally\n**Note**: you can chose the metric to evaluate the model by your own, this example contains only a basic scenario."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from sklearn import metrics\nimport numpy as np \n\n\npredictions = pipeline_model.predict(test_X)\nprint('MAE:', metrics.mean_absolute_error(y_true, predictions))\nprint('MSE:', metrics.mean_squared_error(y_true, predictions))\nprint('r2_score:', r2_score(y_true, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_true, predictions)))", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "MAE: 0.5063604497585167\nMSE: 0.6969533173036409\nr2_score: 0.9934985472923176\nRMSE: 0.8348372998995918\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"scoring\"></a>\n## Deploy and Score\n\nIn this section you will learn how to deploy and score pipeline model as webservice using WML instance."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "# @hidden cell\nwml_credentials = {\n  \"apikey\": \"goh8USQL6eOqtUf5v6gRdQlZdi0c7xeco3mwSuUTDml_\",\n  \"iam_apikey_description\": \"Auto-generated for key f47f2e71-9202-427d-a5e0-f1218cbd8510\",\n  \"iam_apikey_name\": \"Service credentials-1\",\n  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/be7b73d38fca445daf14fb6ae2b0f614::serviceid:ServiceId-5e88a2b4-4c64-4bfb-9618-51d7aaf24514\",\n  \"instance_id\": \"e295d7a4-e2c6-4261-bd28-dbe0596e21c4\",\n  \"url\": \"https://eu-gb.ml.cloud.ibm.com\"\n}", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"deployment\"></a>\n### Create deployment\n\n**Action**: If you want to deploy refined pipeline please change the `pipeline_model` to `new_pipeline`.\n \nIf you prefer you can also change the `deployment_name`."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from watson_machine_learning_client.deployment import WebService\n\nservice = WebService(wml_credentials)\n\nservice.create(\n    model=pipeline_model,\n    metadata=experiment_metadata,\n    deployment_name=f'{pipeline_name}_webservice'\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Deployment object could be printed to show basic information:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "print(service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To be able to show all available information about deployment use `.get_params()` method:"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "service.get_params()", "execution_count": null, "outputs": []}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"online_scoring\"></a>\n### Score webservice\nYou can make scoring request by calling `score()` on deployed pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "predictions = service.score(payload=holdout_df.drop([experiment_metadata['prediction_column']], axis=1).iloc[:10])\npredictions", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "{'predictions': [{'fields': ['prediction'],\n   'values': [[70.39000244140625],\n    [67.16999740600586],\n    [66.4000015258789],\n    [75.6099983215332],\n    [63.790000915527344],\n    [56.97999954223633],\n    [70.68000030517578],\n    [54.04000053405762],\n    [74.86999969482422],\n    [72.10999755859375]]}]}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "print(service.scoring_url)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "https://eu-gb.ml.cloud.ibm.com/v4/deployments/c8e101fa-4ede-49aa-b1cd-5cee3a93cd95/predictions\n", "name": "stdout"}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"authors\"></a>\n### Authors\n\nLicensed Materials - Copyright \u00a9 2020 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs  \n(or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms),  \nsuch agreements located in the link below. Specifically, the Source Components and Sample Materials clause  \nincluded in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BHU2B7&title=IBM%20Watson%20Studio%20Auto-generated%20Notebook%20V2.1\">License Terms</a>  \n\n___"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}